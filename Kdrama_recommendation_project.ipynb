{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Kdrama recommendation project"
      ],
      "metadata": {
        "id": "hmP5gBiAK-af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Required Libraries:"
      ],
      "metadata": {
        "id": "EQmZfa5NLDTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll need to install libraries such as BeautifulSoup, requests, pandas, scikit-learn, scikit-surprise, and Flask."
      ],
      "metadata": {
        "id": "Bmf42ppHLAtn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVfCWHr6KsVF",
        "outputId": "b2adf999-ef3b-46ea-c02b-5c03553fb8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357287 sha256=051ad1cba298d15a234e080d69415f8a1ec5e8050153855a9729dd07277242d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4 requests pandas scikit-surprise Flask\n",
        "!pip install textblob  # For sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.  Data Collection and Preprocessing"
      ],
      "metadata": {
        "id": "OacVYg4_LNue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Web Scraping with BeautifulSoup"
      ],
      "metadata": {
        "id": "nMw3anXILYYt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's the full code to scrape Kdrama information from MyDramaList, including extracting genres from individual drama pages:"
      ],
      "metadata": {
        "id": "rkH3zyIiLlFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Base URL for MyDramaList\n",
        "base_url = \"https://mydramalist.com\"\n",
        "\n",
        "# URL for the Kdrama search results\n",
        "search_url = \"https://mydramalist.com/search?adv=titles&ty=68\"\n",
        "\n",
        "# Send a request to the search results page\n",
        "response = requests.get(search_url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Find the drama entries\n",
        "dramas = soup.find_all('div', class_='box')\n",
        "\n",
        "# Extract data and store it in a list\n",
        "drama_data = []\n",
        "\n",
        "for drama in dramas:\n",
        "    # Find the title and link to the individual drama page\n",
        "    title_tag = drama.find('h6', class_='text-primary title')\n",
        "    title = title_tag.find('a').text.strip() if title_tag else 'Unknown'\n",
        "\n",
        "    # Get the link to the individual drama page\n",
        "    drama_link = title_tag.find('a')['href'] if title_tag else None\n",
        "    full_drama_url = base_url + drama_link if drama_link else None\n",
        "\n",
        "    # Default genres to unknown, will be updated later\n",
        "    genres = 'Unknown'\n",
        "\n",
        "    if full_drama_url:\n",
        "        # Visit the individual drama page to extract genres\n",
        "        try:\n",
        "            drama_response = requests.get(full_drama_url)\n",
        "            drama_soup = BeautifulSoup(drama_response.content, 'html.parser')\n",
        "\n",
        "            # Find the genres from the individual drama page\n",
        "            genre_elements = drama_soup.select('li.show-genres a')\n",
        "            genres = ', '.join([genre.text.strip() for genre in genre_elements])\n",
        "\n",
        "            # Optional: Add a delay to avoid overloading the server\n",
        "            time.sleep(1)  # Sleep for 1 second between requests\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching details from {full_drama_url}: {e}\")\n",
        "\n",
        "    # Find the rating\n",
        "    rating_tag = drama.find('span', class_='score')\n",
        "    rating = float(rating_tag.text.strip()) if rating_tag else 0.0\n",
        "\n",
        "    # Append the collected data\n",
        "    drama_data.append({\n",
        "        'title': title,\n",
        "        'genres': genres,\n",
        "        'rating': rating\n",
        "    })\n",
        "\n",
        "# Convert the data into a DataFrame\n",
        "df = pd.DataFrame(drama_data)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Save the data to a CSV file for later use\n",
        "df.to_csv('kdramas.csv', index=False)\n",
        "\n",
        "# Download the CSV file in Colab\n",
        "from google.colab import files\n",
        "files.download('kdramas.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "fJMyh53yLLHF",
        "outputId": "201081bd-ffaf-458f-8a9c-d920b2e32a39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        title                           genres  rating\n",
            "0        Twinkling Watermelon   Romance, Youth, Drama, Fantasy     9.2\n",
            "1              Move to Heaven                      Life, Drama     9.1\n",
            "2           Weak Hero Class 1             Action, Youth, Drama     9.1\n",
            "3  Hospital Playlist Season 2    Romance, Life, Drama, Medical     9.1\n",
            "4               Lovely Runner  Music, Comedy, Romance, Fantasy     9.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_702eebfd-fe3e-48af-971e-d906e7f70ffe\", \"kdramas.csv\", 1109)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2  Data Cleaning and Feature Engineering"
      ],
      "metadata": {
        "id": "ebQWMFiPLpp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file\n",
        "df = pd.read_csv('kdramas.csv')\n",
        "\n",
        "# Remove duplicates\n",
        "df.drop_duplicates(subset='title', inplace=True)\n",
        "\n",
        "# Handle missing values\n",
        "df.fillna({'genres': 'Unknown', 'rating': 0}, inplace=True)\n",
        "\n",
        "# Normalize text\n",
        "df['genres'] = df['genres'].str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "\n",
        "# One-hot encode the genres\n",
        "df = pd.concat([df, df['genres'].str.get_dummies(sep=',')], axis=1)\n",
        "\n",
        "# Display the cleaned data\n",
        "print(df.head())\n",
        "\n",
        "# Simulate user data\n",
        "user_ids = [f\"user_{i}\" for i in range(1, 101)]  # 100 dummy users\n",
        "\n",
        "# Create a new DataFrame for user-item interactions\n",
        "user_item_data = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    for user_id in user_ids:\n",
        "        # Randomly assign a rating between 1 and 10\n",
        "        user_rating = random.uniform(1, 10)\n",
        "        user_item_data.append((user_id, row['title'], user_rating))\n",
        "\n",
        "# Convert to DataFrame\n",
        "user_item_df = pd.DataFrame(user_item_data, columns=['user_id', 'title', 'rating'])\n",
        "\n",
        "# Display the user-item interactions\n",
        "print(user_item_df.head())\n",
        "\n",
        "# Use user-item_df for collaborative filtering\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3749d6-ec1c-40b2-ff55-5fe12fcd21b3",
        "id": "6j2LupAyLpp9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                        title                        genres  rating  \\\n",
            "0        Twinkling Watermelon   romance youth drama fantasy     9.2   \n",
            "1              Move to Heaven                    life drama     9.1   \n",
            "2           Weak Hero Class 1            action youth drama     9.1   \n",
            "3  Hospital Playlist Season 2    romance life drama medical     9.1   \n",
            "4               Lovely Runner  music comedy romance fantasy     9.1   \n",
            "\n",
            "   action historical romance fantasy  action thriller mystery supernatural  \\\n",
            "0                                  0                                     0   \n",
            "1                                  0                                     0   \n",
            "2                                  0                                     0   \n",
            "3                                  0                                     0   \n",
            "4                                  0                                     0   \n",
            "\n",
            "   action youth drama  comedy romance life youth  \\\n",
            "0                   0                          0   \n",
            "1                   0                          0   \n",
            "2                   1                          0   \n",
            "3                   0                          0   \n",
            "4                   0                          0   \n",
            "\n",
            "   comedy romance wuxia fantasy  historical comedy drama political  \\\n",
            "0                             0                                  0   \n",
            "1                             0                                  0   \n",
            "2                             0                                  0   \n",
            "3                             0                                  0   \n",
            "4                             0                                  0   \n",
            "\n",
            "   life drama  ...  mystery romance wuxia fantasy  mystery wuxia  \\\n",
            "0           0  ...                              0              0   \n",
            "1           1  ...                              0              0   \n",
            "2           0  ...                              0              0   \n",
            "3           0  ...                              0              0   \n",
            "4           0  ...                              0              0   \n",
            "\n",
            "   mystery wuxia fantasy  psychological life drama  romance drama melodrama  \\\n",
            "0                      0                         0                        0   \n",
            "1                      0                         0                        0   \n",
            "2                      0                         0                        0   \n",
            "3                      0                         0                        0   \n",
            "4                      0                         0                        0   \n",
            "\n",
            "   romance life drama medical  romance youth drama fantasy  \\\n",
            "0                           0                            1   \n",
            "1                           0                            0   \n",
            "2                           0                            0   \n",
            "3                           1                            0   \n",
            "4                           0                            0   \n",
            "\n",
            "   thriller mystery scifi  thriller romance crime melodrama  unknown  \n",
            "0                       0                                 0        0  \n",
            "1                       0                                 0        0  \n",
            "2                       0                                 0        0  \n",
            "3                       0                                 0        0  \n",
            "4                       0                                 0        0  \n",
            "\n",
            "[5 rows x 22 columns]\n",
            "  user_id                 title    rating\n",
            "0  user_1  Twinkling Watermelon  8.244153\n",
            "1  user_2  Twinkling Watermelon  2.033527\n",
            "2  user_3  Twinkling Watermelon  7.168817\n",
            "3  user_4  Twinkling Watermelon  6.613000\n",
            "4  user_5  Twinkling Watermelon  7.977550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.  Build the Recommendation System"
      ],
      "metadata": {
        "id": "qBLaexqRLyTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Collaborative Filtering with Surprise"
      ],
      "metadata": {
        "id": "tWy2u7v4LyTv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's update the collaborative filtering code using the user_item_df DataFrame."
      ],
      "metadata": {
        "id": "Ij-Fd_HfTp9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import Dataset, Reader\n",
        "from surprise import KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Create a reader for the data\n",
        "reader = Reader(rating_scale=(1, 10))\n",
        "\n",
        "# Load data into Surprise\n",
        "data = Dataset.load_from_df(user_item_df[['user_id', 'title', 'rating']], reader)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# Define the algorithm\n",
        "algo = KNNBasic()\n",
        "\n",
        "# Train the algorithm on the training set\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Function to get top N recommendations\n",
        "def get_top_n(predictions, n=10):\n",
        "    top_n = {}\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        if uid not in top_n:\n",
        "            top_n[uid] = []\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Sort the predictions for each user\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Calculate RMSE for the predictions\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "# Get recommendations for all users in the test set\n",
        "top_n_recommendations = get_top_n(predictions, n=5)\n",
        "\n",
        "# List users available in the predictions\n",
        "available_users = list(top_n_recommendations.keys())\n",
        "print(f\"Available users for recommendations: {available_users[:10]}\")  # Print first 10 users\n",
        "\n",
        "# Choose a sample user from available users\n",
        "sample_user = available_users[0]  # Use the first available user\n",
        "\n",
        "print(f\"\\nTop 5 recommendations for {sample_user}:\")\n",
        "try:\n",
        "    for item_id, rating in top_n_recommendations[sample_user]:\n",
        "        print(f\"{item_id} with estimated rating {rating:.2f}\")\n",
        "except KeyError:\n",
        "    print(f\"No recommendations available for user: {sample_user}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49048221-2485-40bd-8c66-f5c32a586e14",
        "id": "cnlZ3JYpLyTv"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 2.6119\n",
            "Available users for recommendations: ['user_20', 'user_53', 'user_43', 'user_86', 'user_52', 'user_64', 'user_68', 'user_78', 'user_6', 'user_72']\n",
            "\n",
            "Top 5 recommendations for user_20:\n",
            "Hidden Love with estimated rating 5.78\n",
            "Unknown with estimated rating 5.77\n",
            "My Mister with estimated rating 5.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Improve the Collaborative Filtering Model"
      ],
      "metadata": {
        "id": "CV9ElcKDUf8S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment with Different Algorithms:\n",
        "\n",
        "Surprise library options: Try using other algorithms such as KNNWithMeans, SVD, or SlopeOne to see if they perform better than KNNBasic.\n",
        "\n",
        "Tune hyperparameters: Use GridSearchCV from the surprise library to find the optimal parameters for the selected algorithms."
      ],
      "metadata": {
        "id": "AfCA5iaUUcHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from surprise import SVD, KNNWithMeans\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_factors': [50, 100],\n",
        "    'n_epochs': [20, 30],\n",
        "    'lr_all': [0.005, 0.010],\n",
        "    'reg_all': [0.02, 0.1]\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "# Best RMSE score\n",
        "print(gs.best_score['rmse'])\n",
        "\n",
        "# Combination of parameters that gave the best RMSE score\n",
        "print(gs.best_params['rmse'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjJ_Y4bFUbDY",
        "outputId": "1429a9fc-7cf8-483c-bb81-15895a79993d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.698366148564403\n",
            "{'n_factors': 100, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2  Content-Based Filtering with Cosine Similarity"
      ],
      "metadata": {
        "id": "TYnBsezHLyTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the title exists in the DataFrame\n",
        "print(\"Available titles in the DataFrame:\")\n",
        "print(df['title'].head(10))  # Print first 10 titles for quick inspection\n",
        "\n",
        "# Check if 'Crash Landing on You' is present\n",
        "if 'Crash Landing on You' in df['title'].values:\n",
        "    print(\"'Crash Landing on You' is available in the DataFrame.\")\n",
        "else:\n",
        "    print(\"'Crash Landing on You' is not available in the DataFrame.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRc1gcOVU61X",
        "outputId": "daf4d6d2-6652-406f-a561-d30c9c3b35fd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available titles in the DataFrame:\n",
            "0          Twinkling Watermelon\n",
            "1                Move to Heaven\n",
            "2             Weak Hero Class 1\n",
            "3    Hospital Playlist Season 2\n",
            "4                 Lovely Runner\n",
            "5               Nirvana in Fire\n",
            "6                Flower of Evil\n",
            "7              Alchemy of Souls\n",
            "8                        Moving\n",
            "9             Hospital Playlist\n",
            "Name: title, dtype: object\n",
            "'Crash Landing on You' is not available in the DataFrame.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# TF-IDF Vectorizer for genres\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(df['genres'])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Function to get recommendations based on content\n",
        "def get_content_recommendations(title, cosine_sim=cosine_sim):\n",
        "    idx = df[df['title'] == title].index[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:6]  # Top 5 similar items\n",
        "    drama_indices = [i[0] for i in sim_scores]\n",
        "    return df['title'].iloc[drama_indices]\n",
        "\n",
        "# Example usage\n",
        "print(get_content_recommendations('Lovely Runner'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7534e1e8-2979-4a50-a0f4-9f641256184e",
        "id": "6YzuOxfrLyTv"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16    Joy of Life Season 2\n",
            "10              Reply 1988\n",
            "15             Hidden Love\n",
            "0     Twinkling Watermelon\n",
            "11             Joy of Life\n",
            "Name: title, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Develop a Hybrid Recommendation System"
      ],
      "metadata": {
        "id": "6omKz9PDO_Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine collaborative and content-based filtering for a more robust recommendation engine:\n",
        "\n",
        "Hybrid Approach:\n",
        "\n",
        "*   Use collaborative filtering for personalization and content-based filtering for exploring similar dramas.\n",
        "*   Aggregate recommendations from both methods, possibly weighting them based on their reliability.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KY93SVorVe09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_recommendations(user_id, title, n=5):\n",
        "    collab_recs = [iid for iid, _ in top_n_recommendations.get(user_id, [])]\n",
        "    content_recs = list(get_content_recommendations(title))\n",
        "    # Merge recommendations and prioritize unique ones\n",
        "    hybrid_recs = list(dict.fromkeys(collab_recs + content_recs))\n",
        "    return hybrid_recs[:n]\n",
        "\n",
        "# Example usage for a specific user and title\n",
        "user_id = available_users[0]\n",
        "drama_title = 'Lovely Runner'\n",
        "print(hybrid_recommendations(user_id, drama_title))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtdT10GAPDaA",
        "outputId": "93665271-708c-467f-af72-b82e8e8afa19"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hidden Love', 'Unknown', 'My Mister', 'Joy of Life Season 2', 'Reply 1988']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  5: Develop the User Interface"
      ],
      "metadata": {
        "id": "VhI25JcWPGFE"
      }
    }
  ]
}